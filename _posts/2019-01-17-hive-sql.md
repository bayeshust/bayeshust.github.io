---
layout: post
title: "Hive SQL 介绍及使用"
tagline: ""
description: ""
category: 学习笔记
tags: [hive, sql, hadoop, hbase, ]
last_updated:
---

Hive 是 Hadoop 生态中必不可少的工具，提供了 SQL 方言用于查询存储在 [HDFS](/post/2013/11/hdfs.html) 中的数据和其他与 Hadoop 集成的文件系统（Amazon S3 ，HBase 数据库，Cassandra 的数据）

Hive 最适合数据仓库应用，使用应用进行相关静态数据分析，不需要快速响应得到结果，数据本身不会频繁发生变化。Hive 不是完整的数据库，Hadoop 和 HDFS 的设计约束和局限限制了 Hive 所能胜任的工作。最大的限制就是 Hive 不支持记录级别的更新、插入或者删除。

Hive 不支持 OLTP（联机事务处理）而更接近 OLAP（联机分析技术），如果要对大规模数据使用 OLTP，应该使用 NoSQL 数据库，例如 HBase 等。和大多数 SQL 方言一样，HiveQL 不符合 ANSI SQL 标准，和 常规的 MySQL，SQL Server 支持的 SQL 有很多方面差异，HiveQL 和 MySQL 提供的 SQL 方言最接近。

## 安装 Hive 运行环境
Hive 的运行依赖很多环境，需要一一配置

### JDK
首先保证 Java 运行环境，jdk 1.7 及以上

    java -version

验证

### Hadoop 环境搭建

下载 tar，解压，配置环境变量

    export HADOOP_HOME=/usr/local/hadoop
    export HADDOP_CONF_DIR=$HADOOP_HOME/etc/hadoop

    export HADOOP_MAPRED_HOME=$HADOOP_HOME
    export HADOOP_COMMON_HOME=$HADOOP_HOME

    export HADOOP_HDFS_HOME=$HADOOP_HOME
    export YARN_HOME=$HADOOP_HOME
    export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
    export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib/native"

    export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
    export HADOOP_INSTALL=$HADOOP_HOME

配置完可以查看下版本：

    hadoop version

配置文件

配置 `core-site.xml`

    <property>
      <name>fs.default.name</name>
      <value>hdfs://localhost:9000</value>
    </property>

配置 `hdfs-site.xml`

    <property>
       <name>dfs.replication</name>
       <value>1</value>
    </property>
    <property>
       <name>dfs.name.dir</name>
       <value>file:///home/hadoop/hadoopinfra/hdfs/namenode </value>
    </property>
    <property>
       <name>dfs.data.dir</name>
       <value>file:///home/hadoop/hadoopinfra/hdfs/datanode </value >
    </property>

配置 `yarn-site.xml`

    <property>
       <name>yarn.nodemanager.aux-services</name>
       <value>mapreduce_shuffle</value>
    </property>

配置 `mapred-site.xml`

    cp mapred-site.xml.template mapred-site.xml

添加如下

    <property>
      <name>mapreduce.framework.name</name>
      <value>yarn</value>
    </property

验证，首先格式化 namenode

    hdfs namenode -format

启动 Hadoop dfs

    start-dfs.sh

启动 Yarn Script

    start-yarn.sh

安装成功后访问

    http://localhost:50070/
    http://localhost:8088/

Hive 的大多数工作是使用 Hadoop 的 job，Hive 的行为可以反映出用户所使用的 Hadoop 运行模式。

### Hive 环境搭建
下载 tar，解压，配置环境变量（根据不同的路径配置）

    wget http://archive.apache.org/dist/hive/hive-2.1.0/apache-hive-2.1.0-bin.tar.gz
    tar -xzf apache-hive-2.1.0-bin.tar.gz
    export HIVE_HOME=/home/einverne/apache-hive-2.1.0-bin
    export PATH=$PATH:$HIVE_HOME/bin

配置

    cd $HIVE_HOME/conf
    cp hive-env.sh.template hive-env.sh

编辑 `hive-env.sh`

    export HADOOP_HOME=/usr/local/hadoop

配置 `hive-site.xml`

    cp hive-default.xml.template hive-site.xml

使用 hive 内置的 derby (Apache Derby 非常小巧，核心部分 derby.jar 只有 2M，所以既可以做为单独的数据库服务器使用，也可以内嵌在应用程序中使用），初始化 Derby 数据库：

    schematool -initSchema -dbType derby

验证

    hive --version

进入 hive 之后

    hive> show databases;

查看结果。默认会有一个 default 数据库，至此所有的安装都完成了。

Hive 目录的一些说明：

- `$HIVE_HOME/lib` 下有很多 jar 包，每一个 jar 包提供 Hive 功能中的特定部分。
- `$HIVE_HOME/bin` 目录下包含各种可执行文件，包括 hive 的命令行 CLI。
- Hive 客户端都需要一个 metastoreservice 元数据服务，Hive 使用该服务来存储表模式信息和其他元数据信息。通常会使用一个关系型数据库的表来提供存储。默认情况下，Hive 会使用内置的 Derby SQL 服务，提供有限的单进程服务。
- conf 目录下存放 Hive 配置文件。

Hive 的安装总体过程比较复杂可以具体参考[这里](https://www.tutorialspoint.com/hive/hive_installation.htm)


## 问题
启动 `start-dfs.sh` 时遇到

    19/01/29 18:36:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

需要配置如下环境变量：

    export HADOOP_OPTS="$HADOOP_OPTS -Djava.library.path=$HADOOP_HOME/lib/native"

关于使用 derby 的问题，hive 内嵌一个 derby ，如果要使用内嵌的 derby 那么在 `hive-site.xml` 中需要配置连接字串为：

    <property>
       <name>javax.jdo.option.ConnectionURL</name>
       <value>jdbc:derby:metastore_db;create=true</value>
       <description>JDBC connect string for a JDBC metastore </description>
    </property>

而如果选择单独启动 derby 那么需要配置：

    <property>
       <name>javax.jdo.option.ConnectionURL</name>
       <value>jdbc:derby://localhost:1527/metastore_db;create=true </value>
       <description>JDBC connect string for a JDBC metastore </description>
    </property>

而这个时候则需要[单独的配置启动 derby](https://cwiki.apache.org/confluence/display/Hive/HiveDerbyServerMode).

## 使用

### Metastore
Hive 的元数据都存放在 metastore 中，包括：服务和后台数据。metastore 的配置有三种方式：

- 内置 metastore
- 本地 metastore
- 远程 metastore

在上面的安装步骤中，使用了内置的 Derby 数据库，但这个只适用于本地试验，如果要部署到生产环境还是需要单独配置 Metastore 数据库，使用外部的 Derby 或者 MySQL 等等。

当使用内置的 Derby 并且在本地一个目录中启动终端 hive，那么进入 hive shell 时，hive 默认会在当前目录下生成一个 metastore_db 目录，用来保存在 Shell 中的 sql 结果，新建的表，添加的分区等等。

这种存储方式导致同一个目录只能同时有一个 hive 客户端访问，切换目录使用 shell 时，无法查看之前创建的表。

如果要使用 MySQL 那么需要配置几点。首先将 mysql-jdbc-driver.jar 拷贝到 `$HIVE_HOME/lib` 目录下，然后配置 hive-site.xml 文件

    <property>  
      <name>hive.metastore.local</name>  
      <value>true</value>  
    </property>  
    <property>  
      <name>javax.jdo.option.ConnectionURL</name>  
      <value>jdbc:mysql://localhost/hive?createDatabaseIfNotExist=true</value>  
    </property>  
    <property>  
      <name>javax.jdo.option.ConnectionDriverName</name>  
      <value>com.mysql.jdbc.Driver</value>  
    </property>  
    <property>  
      <name>javax.jdo.option.ConnectionUserName</name>  
      <value>hive</value>  
    </property>  
    <property>  
      <name>javax.jdo.option.ConnectionPassword</name>  
      <value>password</value>  
    </property>

### 数据库相关

    CREATE DATABASE demo;
    CREATE DATABASE IF NOT EXISTS demo;
    SHOW DATABASES;
    SHOW DATABASE LIKE 'd.*';
    DESCRIBE DATABASE demo;

### 表

    CREATE TABLE IF NOT EXISTS mydb.employees (
        name    STRING COMMENT 'name',
        age     INT COMMENT 'age',
        salary  FLOAT COMMENT 'salary',
        subordinates    ARRAY<STRING> COMMENT 'Names of subordinates',
        deductions      MAP<STRING, FLOAT> COMMENT 'Keys are deductions name, values are percentages',
        address         STRUCT<street:STRING, city:STRING, state:STRING, zip:INT> COMMENT 'Home address'
    )
    COMMENT 'Description of the table'
    TBLPROPERTIES ('creator'='me', 'create_at'='2019-01-01 00:00:00')
    LOCATION '/user/hive/warehouse/mydb.db/employees';

    DROP TABLE IF EXISTS employees;



## reference

- <https://cwiki.apache.org/confluence/display/Hive/Tutorial>
- <https://www.edureka.co/blog/apache-hive-installation-on-ubuntu>
- <https://blog.csdn.net/hguisu/article/details/7256833>


